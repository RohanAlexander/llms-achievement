---
title: "[Result, but poetic]: Does LLM Use Improve Data Science Education?"
subtitle: "Evidence from a Canadian Undergraduate Statistics Course"
author: 
  - Rohan Alexander
  - Luca Carnegie
thanks: "Code and data are available at: https://github.com/lcarnegie/llms-achievement."
date: today
date-format: long
abstract: "Blah Blah Blah Blah"
format: pdf
number-sections: true
bibliography: references.bib
nocite: | #references.bib entries at end, regardless of intext citation
  @* 
---

```{r setup}
## Workspace Setup ##
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(knitr)
library(kableExtra)
library(lintr)
library(tidyr)

# Import data
survey_data <- read_csv("../data/analysis_data/clean_STA302_postcourse_survey_w24.csv")
```

# Introduction

The rapid advancement of Large Language Models (LLMs) like ChatGPT has had massive effects in all areas of society, with notable increases in productivity within some knowledge-based industries. Recent papers have demonstrated evidence of some productivity increases, in industries ranging from consulting to computer programming.  

On the lower end of productivity increases, @Ben_2024 conducted a randomized control trial with judges in Wisconsin to assess the impact of AI recommendations on bail hearing decisions. The study found that providing AI recommendations did not significantly improve judges' decision-making accuracy. 
On the other hand, @Peng_2023 investigated the significantly positive impact of GitHub Copilot, an LLM-powered coding assistant, on programmer productivity. They conducted an experiment with 95 professional programmers recruited through Upwork. The study found that programmers with access to Copilot completed a standardized programming task 55.8% faster than the control group. In particular, less experienced programmers appeared to benefit more from the tool. 

Examining the middle-ground, a study by @DellAcqua_2023 examined the impact of AI on management consulting tasks through a field experiment with 758 Boston Consulting Group consultants. They found that AI significantly increased performance across various business tasks, with speed increasing by over 25% and quality by more than 40%. However, the study revealed a "jagged technological frontier" where AI excelled in some tasks but struggled with others. Notably, AI usage appeared to level performance differences across ability levels, with lower-performing consultants benefiting the most, similar to that of Peng et al. 

We can see in the current literature that LLMs have had varying levels of impact across different knowledge-intensive industries, with more computer-intensive tasks like programming receiving the highest performance boosts. One area sorely lacking quantitative evidence of performance increases is within higher education, an area where scrutiny of the impact of LLMs and other AI tools has been common. A survey of undergraduate political science students was conducted by @Cahill_2024, revealing widespread use of AI tools like ChatGPT. However, their study also uncovered a significant gap in students' self-perceived competence in using these tools effectively for academic work. 

Student challenges while learning Data Science in particular were explored by @kross2019. By polling instructor-practitioners of Data Science in academia and industry, they found several key challenges that data science students face. The largest challenges they faced were diverse computing backgrounds, integrating various technical workflows, software setup, finding relevant datasets, as well as dealing with the inherent uncertainty of the data analysis process. 

Given the rapid integration of AI tools in educational and professional settings, there is a need to understand how these technologies and students' attitudes toward LLMs affect their  learning and performance. This paper aims to investigate the relationship between academic performance, LLM usage, and students' perceptions of LLMs, using evidence from an exit survey of a third-year undergraduate statistics course at the University of Toronto. By examining how students interact with and perceive LLM tools and how this usage correlates with their grades, we seek to understand the potential benefits and pitfalls of AI integration in data science education.

The remainder of this paper is structured as follows: @sec-data analyzes our survey data; @sec-model models our unstructured data to find fun and cool things; @sec-results lists the results; @sec-discussion discusses the implications of these findings for data science education and for future research and practice in this rapidly evolving field.



# Data {#sec-data}

```{r fig-boilerplate}
#| message: false
#| echo: false
#| warning: false
#| fig-cap: (CHANGE) Boilerplate figure caption 
#| fig-align: center

# survey_data |>
#   ggplot(program_counts, aes(x = "", y = n, fill = program_of_study)) +
#   #put geom type here (put before compilation) +
#   labs(title = "Title!",
#        x = "X label",
#        y = "Y label") +
#   theme_minimal() +
#   scale_fill_discrete(name="Legend Title") +
#   theme(plot.title.position = "plot",
#         plot.title = element_text(hjust = 0.5)
#         )

```

```{r tbl-boilerplate}
#| message: false
#| echo: false
#| warning: false
#| tbl-cap: (CHANGE) Boilerplate table caption 
#| fig-align: center

#Put code below this line

```

```{r fig-gpa-hist}
#| message: false
#| echo: false
#| warning: false
#| tbl-cap: Distribution of Student GPA
#| fig-align: center

#Histogram of GPA

survey_data |>
    ggplot(aes(x = gpa)) +
    geom_histogram(binwidth = 0.1, fill = "skyblue", color = "black") +
    labs(title = "Distribution of Student GPA",
         x = "GPA",
         y = "Frequency") +
    theme_minimal() +
    theme(plot.title.position = "plot",
          plot.title = element_text(hjust = 0.5))

```

```{r fig-year-bar}
#| message: false
#| echo: false
#| warning: false
#| tbl-cap: Distribution of Students by Year
#| fig-align: center

# Change PEY to 4th year
survey_data <- survey_data |>
    mutate(
      year = case_when(
        year == "PEY" ~ "4th",
        year == "5th" ~ "5th+",
        year == "6th" ~ "5th+",
        TRUE ~ year
      )
    )


#Bar plot of year
survey_data |> ggplot(aes(x = year)) +
    geom_bar(fill = "skyblue", color = "black") +
    labs(title = "Distribution of Students by Year",
         x = "Year",
         y = "Frequency") +
    theme_minimal() +
    theme(plot.title.position = "plot",
          plot.title = element_text(hjust = 0.5))

```

```{r fig-programs-pie}
#| message: false
#| echo: false
#| warning: false
#| tbl-cap: Student Self-Perception of Writing Ease
#| fig-align: center

#Pie chart of program of study

program_counts <- survey_data |> 
  count(program_of_study)

ggplot(program_counts, aes(x = "", y = n, fill = program_of_study)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar("y") +
  labs(title = "Distribution of Unique Programs",
       x = NULL,
       y = NULL) +
  theme_minimal() +
  scale_fill_discrete(name="Program") +
  theme(axis.text.x = element_blank(),  # Remove x-axis text
        axis.title.x = element_blank(), # Remove x-axis title
        plot.title = element_text(hjust = 1.35)
        )


```

```{r fig-response-time-hist}
#| message: false
#| echo: false
#| warning: false
#| fig-cap: Distribution of Survey Response Times
#| fig-align: center

#Trim values to histogram

plot_data <- survey_data |>
    filter(mins_complete < 1000)

plot_data |>
    ggplot(aes(x = mins_complete)) +
    geom_histogram(binwidth = 0.1, fill = "skyblue", color = "black") +
    labs(title = "Distribution of Survey Response Times",
         x = "Time (Mins)",
         y = "Frequency") +
    theme_minimal() +
    theme(plot.title.position = "plot",
          plot.title = element_text(hjust = 0.5))

```


```{r fig-writing-multibar-1}
#| message: false
#| echo: false
#| warning: false
#| tbl-cap: Student Self-Perceptions on Writing, Part 1
#| fig-align: center

# Create a multi-bar plot for writing perceptions grouped by response 

#Select first three statements
writing_perceptions <- survey_data |>
  select(
    writing_is_easy_for_me, 
    i_like_to_write, 
    i_believe_it_is_important_to_be_a_good_writer
  )

writing_perceptions_long <- writing_perceptions |>
  pivot_longer(cols = everything(), names_to = "Statements", values_to = "Response") |>
  mutate(
    Statements = case_when(
      Statements == "writing_is_easy_for_me" ~ "\"Writing is easy for me\"",
      Statements == "i_like_to_write" ~ "\"I like to write\"",
      Statements == "i_believe_it_is_important_to_be_a_good_writer" ~ "\"I believe it is important\n to be a good writer\"",
      TRUE ~ Statements
    ), 
    Response = case_when(
      Response == "This is a lot like me" ~ "A lot like me",
      Response == "This is very different to me" ~ "Very different from me",
      Response == "This somewhat describes me" ~ "Somewhat describes me",
    )
  ) |>
  filter(!is.na(Response))

#Taken from: https://stackoverflow.com/questions/52297978/decrease-overal-legend-size-elements-and-text
addSmallLegend <- function(myPlot, pointSize = 0.5, textSize = 3, spaceLegend = 0.1) {
    myPlot +
        guides(shape = guide_legend(override.aes = list(size = pointSize)),
               color = guide_legend(override.aes = list(size = pointSize))) +
        theme(legend.title = element_text(size = textSize), 
              legend.text  = element_text(size = textSize),
              legend.key.size = unit(spaceLegend, "lines"))
}

# Make the plot
multi_bar <- writing_perceptions_long |>
  ggplot(aes(x = Response, fill = Statements)) +
  geom_bar(position = "dodge", stat = "count") +
  labs(title = "Student Self-Perceptions on Writing",
       x = "Response",
       y = "Frequency") +
  theme_minimal() +
  theme(plot.title.position = "plot",
        plot.title = element_text(hjust = 0.5),
        legend.position= "bottom", 
      )

multi_bar <- addSmallLegend(multi_bar, pointSize = 0.5, textSize = 10, spaceLegend = 0.8)

multi_bar

# TODO: Fix label, Fix Legend title, Fix legibility of Response 

```

```{r fig-writing-multibar-2}
#| message: false
#| echo: false
#| warning: false
#| tbl-cap: Student Self-Perceptions on Writing, Part 2
#| fig-align: center

# Create a multi-bar plot for writing perceptions grouped by response 

# Select last three statements
writing_perceptions <- survey_data |>
  select(
    when_i_edit_it_is_easy_for_me_to_catch_my_mistakes, 
    i_feel_confident_sharing_my_writing, 
    i_am_confident_in_my_overall_writing_ability
  )

writing_perceptions_long <- writing_perceptions |>
  pivot_longer(cols = everything(), names_to = "Statements", values_to = "Response") |>
  mutate(
      Statements = case_when(
      Statements == "when_i_edit_it_is_easy_for_me_to_catch_my_mistakes" ~ "\"When I edit, it is easy to\n catch my own mistakes\"",
      Statements == "i_feel_confident_sharing_my_writing" ~ "\"I feel confident\n sharing my writing\"",
      Statements == "i_am_confident_in_my_overall_writing_ability" ~ "\"I am confident in\n my own writing ability\"",
      TRUE ~ Statements
    ), 
    Response = case_when(
      Response == "This is a lot like me" ~ "A lot like me",
      Response == "This is very different to me" ~ "Very different from me",
      Response == "This somewhat describes me" ~ "Somewhat describes me",
    )
  ) |>
  filter(!is.na(Response))

#Taken from: https://stackoverflow.com/questions/52297978/decrease-overal-legend-size-elements-and-text
addSmallLegend <- function(myPlot, pointSize = 0.5, textSize = 3, spaceLegend = 0.1) {
    myPlot +
        guides(shape = guide_legend(override.aes = list(size = pointSize)),
               color = guide_legend(override.aes = list(size = pointSize))) +
        theme(legend.title = element_text(size = textSize), 
              legend.text  = element_text(size = textSize),
              legend.key.size = unit(spaceLegend, "lines"))
}

# Make the plot
multi_bar <- writing_perceptions_long |>
  ggplot(aes(x = Response, fill = Statements)) +
  geom_bar(position = "dodge", stat = "count") +
  labs(title = "Student Self-Perceptions on Writing",
       x = "Response",
       y = "Frequency") +
  theme_minimal() +
  theme(plot.title.position = "plot",
        plot.title = element_text(hjust = 0.5),
        legend.position= "bottom", 
      )

multi_bar <- addSmallLegend(multi_bar, pointSize = 0.5, textSize = 10, spaceLegend = 0.8)

multi_bar
```


```{r fig-coding-multibar-1}
#| message: false
#| echo: false
#| warning: false
#| tbl-cap: Student Self-Perceptions on Coding, Part 1
#| fig-align: center

# Create a multi-bar plot for writing perceptions grouped by response 

#Select first three statements
writing_perceptions <- survey_data |>
  select(
    coding_is_easy_for_me,
    i_like_to_code,
    i_believe_it_is_important_to_be_a_good_coder
  )

writing_perceptions_long <- writing_perceptions |>
  pivot_longer(cols = everything(), names_to = "Statements", values_to = "Response") |>
  mutate(
    Statements = case_when(
      Statements == "coding_is_easy_for_me" ~ "\"Coding is easy for me\"",
      Statements == "i_like_to_code" ~ "\"I like to code\"",
      Statements == "i_believe_it_is_important_to_be_a_good_coder" ~ "\"I believe it is important\n to be a good coder\"",
      TRUE ~ Statements
    ), 
    Response = case_when(
      Response == "This is a lot like me" ~ "A lot like me",
      Response == "This is very different to me" ~ "Very different from me",
      Response == "This somewhat describes me" ~ "Somewhat describes me",
    )
  ) |>
  filter(!is.na(Response))

#Taken from: https://stackoverflow.com/questions/52297978/decrease-overal-legend-size-elements-and-text
addSmallLegend <- function(myPlot, pointSize = 0.5, textSize = 3, spaceLegend = 0.1) {
    myPlot +
        guides(shape = guide_legend(override.aes = list(size = pointSize)),
               color = guide_legend(override.aes = list(size = pointSize))) +
        theme(legend.title = element_text(size = textSize), 
              legend.text  = element_text(size = textSize),
              legend.key.size = unit(spaceLegend, "lines"))
}

# Make the plot
multi_bar <- writing_perceptions_long |>
  ggplot(aes(x = Response, fill = Statements)) +
  geom_bar(position = "dodge", stat = "count") +
  labs(title = "Student Self-Perceptions of Coding",
       x = "Response",
       y = "Frequency") +
  theme_minimal() +
  theme(plot.title.position = "plot",
        plot.title = element_text(hjust = 0.5),
        legend.position= "bottom", 
      )

multi_bar <- addSmallLegend(multi_bar, pointSize = 0.5, textSize = 10, spaceLegend = 0.8)

multi_bar

```

```{r fig-coding-multibar-2}
#| message: false
#| echo: false
#| warning: false
#| tbl-cap: Student Self-Perceptions on Coding, Part 2
#| fig-align: center

# Create a multi-bar plot for writing perceptions grouped by response 

#Select first three statements
writing_perceptions <- survey_data |>
  select(
    when_i_check_my_code_it_is_easy_for_me_to_catch_my_mistakes, 
    i_feel_confident_sharing_my_code,
    i_am_confident_in_my_overall_coding_ability
  )

writing_perceptions_long <- writing_perceptions |>
  pivot_longer(cols = everything(), names_to = "Statements", values_to = "Response") |>
  mutate(
    Statements = case_when(
      Statements == "when_i_check_my_code_it_is_easy_for_me_to_catch_my_mistakes" ~ "\"When I check my code, it is\n easy for me to catch my mistakes\"",
      Statements == "i_feel_confident_sharing_my_code" ~ "\"I feel confident sharing my code\"",
      Statements == "i_am_confident_in_my_overall_coding_ability" ~ "\"I am confident in\n my overall coding ability\"",
      TRUE ~ Statements
    ), 
    Response = case_when(
      Response == "This is a lot like me" ~ "A lot like me",
      Response == "This is very different to me" ~ "Very different from me",
      Response == "This somewhat describes me" ~ "Somewhat describes me",
    )
  ) |>
  filter(!is.na(Response))

#Taken from: https://stackoverflow.com/questions/52297978/decrease-overal-legend-size-elements-and-text
addSmallLegend <- function(myPlot, pointSize = 0.5, textSize = 3, spaceLegend = 0.1) {
    myPlot +
        guides(shape = guide_legend(override.aes = list(size = pointSize)),
               color = guide_legend(override.aes = list(size = pointSize))) +
        theme(legend.title = element_text(size = textSize), 
              legend.text  = element_text(size = textSize),
              legend.key.size = unit(spaceLegend, "lines"))
}

# Make the plot
multi_bar <- writing_perceptions_long |>
  ggplot(aes(x = Response, fill = Statements)) +
  geom_bar(position = "dodge", stat = "count") +
  labs(title = "Student Self-Perceptions of Coding",
       x = "Response",
       y = "Frequency") +
  theme_minimal() +
  theme(plot.title.position = "plot",
        plot.title = element_text(hjust = 0.5),
        legend.position= "bottom", 
      )

multi_bar <- addSmallLegend(multi_bar, pointSize = 0.4, textSize = 8.5, spaceLegend = 0.8)

multi_bar

```

# Model {#sec-model}

The goal of our modelling strategy is twofold. Firstly,...

Here we briefly describe the Bayesian analysis model used to investigate... Background details and diagnostics are included in [Appendix -@sec-model-details].

## Model set-up

Define $y_i$ as the number of seconds that the plane remained aloft. Then $\beta_i$ is the wing width and $\gamma_i$ is the wing length, both measured in millimeters.  

\begin{align} 
y_i|\mu_i, \sigma &\sim \mbox{Normal}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_i + \gamma_i\\
\alpha &\sim \mbox{Normal}(0, 2.5) \\
\beta &\sim \mbox{Normal}(0, 2.5) \\
\gamma &\sim \mbox{Normal}(0, 2.5) \\
\sigma &\sim \mbox{Exponential}(1)
\end{align}

We run the model in R [@citeR] using the `rstanarm` package of @rstanarm. We use the default priors from `rstanarm`.


### Model justification

We expect a positive relationship between the size of the wings and time spent aloft. In particular...

We can use maths by including latex between dollar signs, for instance $\theta$.


# Results {#sec-results}

Our results are summarized in @tbl-modelresults.







# Discussion {#sec-discussion}

## First discussion point {#sec-first-point}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this. 

## Second discussion point

## Third discussion point

## Weaknesses and next steps

Weaknesses and next steps should also be included.

\newpage

\appendix

# Appendix {-}


# Additional data details

# Model details {#sec-model-details}

## Posterior predictive check

In ... we implement a posterior predictive check. This shows...

In ... we compare the posterior with the prior. This shows... 


## Diagnostics

... is a trace plot. It shows... This suggests...

... is a Rhat plot. It shows... This suggests...



\newpage


# References



# Self-reported LLM usage and results on a datascience project: Evidence from a Canadian undergraduate data science course

## Overview

To help understand the effect of Large Language Models (LLMs) on data science practice we examine the extent to which LLM usage is correlated with the mark that a student gets on a final paper in a classroom data science setting. We find no clear relationship between more extensive LLM usage and the studentâ€™smark. Despite the classroom setting used for evaluation, the particular activity of interest reflects the work done by professional data scientists. Our finding suggests the need for more extensive work evaluating how LLMs can be integrated into the data science workflow in a way that provides value.

## File structure

The repo is structured as:

-   `data/raw_data` contains the raw data.
-   `data/analysis_data` contains the cleaned dataset that was constructed.
-   `model` contains fitted models.
-   `other` contains relevant literature, details about LLM chat interactions, and sketches.
-   `paper` contains the files used to generate the paper, including the Quarto document and reference bibliography file, as well as the PDF of the paper. 
-   `scripts` contains the R scripts used to simulate, download and clean data.

## Statement on LLM usage

Aspects of the code were written with the help of GitHub Copilot and GPT-4o. Aspects of the paper were written with the help of Claude-3.5 Sonnet. Rohan Alexander takes complete and final responsibility for the content of both code and text.

# Self-reported LLM usage and results on a datascience project: Evidence from a Canadian undergraduate data science course

## Overview

To help understand the effect of Large Language Models (LLMs) on data science practice we examine the extent to which LLM usage is correlated with the mark that a student gets on a final paper in a classroom data science setting. We find some very mild evidence from this observational study that LLM usage may be associated with better scores, but our main conclusion is that there is no clear relationship between more extensive LLM usage and the student's mark. Despite the classroom setting used for evaluation, the particular activity of interest reflects the work done by professional data scientists. Our finding suggests the need for more extensive work evaluating how LLMs can be integrated into the data science workflow in a way that provides value.

## File structure

The repo is structured as:

-   `data` contains the data.
-   `model` contains fitted models.
-   `other` contains relevant literature and a copy of the survey questions.
-   `paper` contains the files used to generate the paper, including the Quarto document and reference bibliography file, as well as the PDF of the paper. 
-   `scripts` contains the R scripts used to simulate and model the data.

## Statement on LLM usage

Aspects of the code were written with the help of GitHub Copilot and GPT-4o. Aspects of the paper were written with the help of Claude-3.5 Sonnet.
